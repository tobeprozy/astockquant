#!/usr/bin/env python3
"""
Enhanced UDF (Universal Data Feed) Server for TradingView
æ”¯æŒæ›´çœŸå®çš„è‚¡ç¥¨æ•°æ®æ¨¡æ‹Ÿï¼ŒåŒ…æ‹¬æŠ€æœ¯æŒ‡æ ‡å’Œå¸‚åœºè¡Œä¸ºæ¨¡æ‹Ÿ
"""

import sys
import time
import random
import datetime
import math
from http.server import HTTPServer, BaseHTTPRequestHandler
import urllib.parse
import json
import pandas as pd
import numpy as np
from dataclasses import dataclass
from typing import Dict, List, Optional

@dataclass
class StockConfig:
    """è‚¡ç¥¨é…ç½®ç±»"""
    symbol: str
    name: str
    base_price: float
    volatility: float  # æ³¢åŠ¨ç‡
    trend: float      # è¶‹åŠ¿ (æ­£æ•°ä¸Šæ¶¨ï¼Œè´Ÿæ•°ä¸‹è·Œ)
    sector: str

# é¢„å®šä¹‰çš„è‚¡ç¥¨é…ç½®
STOCK_CONFIGS = {
    'AAPL': StockConfig('AAPL', 'Apple Inc.', 150.0, 0.02, 0.0005, 'Technology'),
    'MSFT': StockConfig('MSFT', 'Microsoft Corporation', 300.0, 0.018, 0.0003, 'Technology'),
    'GOOG': StockConfig('GOOG', 'Alphabet Inc.', 2500.0, 0.025, 0.0002, 'Technology'),
    'TSLA': StockConfig('TSLA', 'Tesla Inc.', 800.0, 0.035, 0.001, 'Automotive'),
    'BABA': StockConfig('BABA', 'Alibaba Group', 200.0, 0.03, -0.0002, 'E-commerce'),
    'AMZN': StockConfig('AMZN', 'Amazon.com Inc.', 3200.0, 0.022, 0.0004, 'E-commerce'),
    'NVDA': StockConfig('NVDA', 'NVIDIA Corporation', 400.0, 0.04, 0.002, 'Technology'),
    'META': StockConfig('META', 'Meta Platforms Inc.', 250.0, 0.028, 0.0001, 'Technology'),
    'NFLX': StockConfig('NFLX', 'Netflix Inc.', 400.0, 0.03, 0.0003, 'Entertainment'),
    'DIS': StockConfig('DIS', 'The Walt Disney Company', 120.0, 0.025, 0.0001, 'Entertainment')
}

class EnhancedStockDataGenerator:
    """å¢å¼ºçš„è‚¡ç¥¨æ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self, config: StockConfig):
        self.config = config
        
    def generate_intraday_data(self, date: datetime.datetime, intervals_per_day: int = 390) -> pd.DataFrame:
        """ç”Ÿæˆå•æ—¥å†…çš„åˆ†é’Ÿçº§æ•°æ®"""
        # åˆ›å»ºäº¤æ˜“æ—¶é—´ (9:30 AM - 4:00 PM EST)
        start_time = date.replace(hour=9, minute=30, second=0, microsecond=0)
        time_intervals = []
        
        for i in range(intervals_per_day):
            time_intervals.append(start_time + datetime.timedelta(minutes=i))
        
        # ç”Ÿæˆä»·æ ¼èµ°åŠ¿ - æ¨¡æ‹Ÿæ—¥å†…äº¤æ˜“æ¨¡å¼
        returns = self._generate_intraday_returns(intervals_per_day)
        
        # è®¡ç®—ä»·æ ¼
        base_price = self.config.base_price * (1 + random.uniform(-0.02, 0.02))
        close_prices = base_price * (1 + returns).cumprod()
        
        # ç”ŸæˆOHLC
        data = []
        for i, time_point in enumerate(time_intervals):
            if i == 0:
                open_price = base_price
            else:
                open_price = data[i-1]['close']
            
            close_price = close_prices[i]
            
            # ç”Ÿæˆé«˜ä½ä»· - è€ƒè™‘çœŸå®çš„ä»·æ ¼æ³¢åŠ¨
            high_factor = random.uniform(1.0, 1 + self.config.volatility * 0.5)
            low_factor = random.uniform(1 - self.config.volatility * 0.5, 1.0)
            
            high_price = max(open_price, close_price) * high_factor
            low_price = min(open_price, close_price) * low_factor
            
            # ç”Ÿæˆæˆäº¤é‡ - æ¨¡æ‹ŸçœŸå®çš„äº¤æ˜“é‡æ¨¡å¼
            volume = self._generate_realistic_volume(i, intervals_per_day)
            
            data.append({
                'datetime': time_point,
                'open': round(open_price, 2),
                'high': round(high_price, 2),
                'low': round(low_price, 2),
                'close': round(close_price, 2),
                'volume': volume
            })
        
        return pd.DataFrame(data)
    
    def generate_daily_data(self, days: int = 365) -> pd.DataFrame:
        """ç”Ÿæˆæ—¥çº¿æ•°æ®"""
        end_date = datetime.datetime.now()
        start_date = end_date - datetime.timedelta(days=days)
        
        # åˆ›å»ºå·¥ä½œæ—¥æ—¥æœŸèŒƒå›´
        dates = pd.date_range(start=start_date, end=end_date, freq='B')
        
        # ç”Ÿæˆæ—¥çº¿æ•°æ®
        returns = self._generate_daily_returns(len(dates))
        
        # åŠ å…¥å­£èŠ‚æ€§å’Œè¶‹åŠ¿
        seasonal_factor = [1 + 0.01 * math.sin(2 * math.pi * i / 252) for i in range(len(dates))]
        trend_factor = [(1 + self.config.trend) ** i for i in range(len(dates))]
        
        # è®¡ç®—ä»·æ ¼åºåˆ—
        base_prices = [self.config.base_price * seasonal_factor[i] * trend_factor[i] for i in range(len(dates))]
        close_prices = np.array(base_prices) * (1 + returns).cumprod()
        
        # ç”ŸæˆOHLCæ•°æ®
        data = []
        for i, date in enumerate(dates):
            if i == 0:
                open_price = self.config.base_price
            else:
                open_price = data[i-1]['close']
            
            close_price = close_prices[i]
            
            # ç”Ÿæˆé«˜ä½ä»·
            daily_range = abs(close_price - open_price) * random.uniform(1.5, 3.0)
            high_price = max(open_price, close_price) + daily_range * random.uniform(0, 0.7)
            low_price = min(open_price, close_price) - daily_range * random.uniform(0, 0.7)
            
            # ç”Ÿæˆæˆäº¤é‡
            base_volume = random.randint(1000000, 5000000)
            volume_multiplier = 1 + abs(close_price - open_price) / open_price * 10  # æ³¢åŠ¨å¤§æ—¶æˆäº¤é‡å¤§
            volume = int(base_volume * volume_multiplier)
            
            data.append({
                'date': date,
                'open': round(open_price, 2),
                'high': round(high_price, 2),
                'low': round(low_price, 2),
                'close': round(close_price, 2),
                'volume': volume
            })
        
        return pd.DataFrame(data)
    
    def _generate_daily_returns(self, length: int) -> np.ndarray:
        """ç”Ÿæˆæ—¥æ”¶ç›Šç‡åºåˆ—"""
        # åŸºç¡€éšæœºæ”¶ç›Š
        returns = np.random.normal(0, self.config.volatility, length)
        
        # æ·»åŠ èšç±»æ³¢åŠ¨æ€§ (GARCHæ•ˆåº”)
        for i in range(1, length):
            if abs(returns[i-1]) > self.config.volatility:
                returns[i] *= 1.5  # å¢åŠ åç»­æ³¢åŠ¨
        
        # æ·»åŠ å‡å€¼å›å½’
        cumulative_return = np.cumsum(returns)
        mean_reversion = -0.001 * cumulative_return
        returns += mean_reversion
        
        return returns
    
    def _generate_intraday_returns(self, length: int) -> np.ndarray:
        """ç”Ÿæˆæ—¥å†…æ”¶ç›Šç‡åºåˆ—"""
        # åˆ›å»ºæ—¥å†…æ¨¡å¼ - å¼€ç›˜å’Œæ”¶ç›˜æ—¶æ³¢åŠ¨è¾ƒå¤§
        time_weights = []
        for i in range(length):
            # å¼€ç›˜30åˆ†é’Ÿå’Œæ”¶ç›˜30åˆ†é’Ÿæ³¢åŠ¨è¾ƒå¤§
            if i < 30 or i > length - 30:
                weight = 1.5
            elif 60 < i < 150:  # åˆç›˜ç›¸å¯¹å¹³é™
                weight = 0.7
            else:
                weight = 1.0
            time_weights.append(weight)
        
        # ç”ŸæˆåŸºç¡€æ”¶ç›Š
        base_returns = np.random.normal(0, self.config.volatility / 20, length)  # æ—¥å†…æ³¢åŠ¨è¾ƒå°
        
        # åº”ç”¨æ—¶é—´æƒé‡
        returns = base_returns * np.array(time_weights)
        
        return returns
    
    def _generate_realistic_volume(self, interval_index: int, total_intervals: int) -> int:
        """ç”ŸæˆçœŸå®çš„æˆäº¤é‡æ¨¡å¼"""
        base_volume = random.randint(10000, 50000)
        
        # å¼€ç›˜å’Œæ”¶ç›˜æˆäº¤é‡è¾ƒå¤§
        if interval_index < 30 or interval_index > total_intervals - 30:
            multiplier = random.uniform(2.0, 4.0)
        elif 60 < interval_index < 150:  # åˆç›˜æˆäº¤é‡è¾ƒå°
            multiplier = random.uniform(0.3, 0.7)
        else:
            multiplier = random.uniform(0.8, 1.5)
        
        return int(base_volume * multiplier)

class EnhancedUDFServer:
    """å¢å¼ºçš„UDFæœåŠ¡å™¨"""
    
    def __init__(self):
        self.generators = {symbol: EnhancedStockDataGenerator(config) 
                          for symbol, config in STOCK_CONFIGS.items()}
        self.cache = {}
        self.cache_ttl = {}
        
    def get_daily_data(self, symbol: str, days: int = 365) -> pd.DataFrame:
        """è·å–æ—¥çº¿æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = f"{symbol}_daily_{days}"
        
        # æ£€æŸ¥ç¼“å­˜
        if (cache_key in self.cache and 
            cache_key in self.cache_ttl and 
            time.time() < self.cache_ttl[cache_key]):
            return self.cache[cache_key]
        
        # ç”Ÿæˆæ–°æ•°æ®
        if symbol in self.generators:
            data = self.generators[symbol].generate_daily_data(days)
            
            # ç¼“å­˜æ•°æ®ï¼ˆç¼“å­˜1å°æ—¶ï¼‰
            self.cache[cache_key] = data
            self.cache_ttl[cache_key] = time.time() + 3600
            
            return data
        
        return pd.DataFrame()

class UDFRequestHandler(BaseHTTPRequestHandler):
    def __init__(self, *args, **kwargs):
        self.server_instance = EnhancedUDFServer()
        super().__init__(*args, **kwargs)
    
    def do_GET(self):
        parsed_path = urllib.parse.urlparse(self.path)
        query_params = urllib.parse.parse_qs(parsed_path.query)
        
        # è®¾ç½®CORSå¤´
        self.send_response(200)
        self.send_header('Content-type', 'application/json')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'X-Requested-With')
        self.end_headers()
        
        try:
            if parsed_path.path == '/config':
                self._handle_config()
            elif parsed_path.path == '/search':
                self._handle_search(query_params)
            elif parsed_path.path == '/symbols':
                self._handle_symbols(query_params)
            elif parsed_path.path == '/history':
                self._handle_history(query_params)
            elif parsed_path.path == '/time':
                self._handle_time()
            else:
                self.send_response(404)
                self.end_headers()
        except Exception as e:
            print(f"Error handling request {self.path}: {e}")
            self.send_response(500)
            self.end_headers()
    
    def _handle_config(self):
        """å¤„ç†é…ç½®è¯·æ±‚"""
        config = {
            "supports_search": True,
            "supports_group_request": False,
            "supports_marks": False,
            "supports_timescale_marks": False,
            "supports_time": True,
            "exchanges": [
                {"value": "", "name": "All Exchanges", "desc": ""},
                {"value": "NASDAQ", "name": "NASDAQ", "desc": "NASDAQ"},
                {"value": "NYSE", "name": "NYSE", "desc": "NYSE"}
            ],
            "symbols_types": [
                {"name": "All types", "value": ""},
                {"name": "Stock", "value": "stock"}
            ],
            "supported_resolutions": ["1", "5", "15", "30", "60", "D", "W", "M"]
        }
        self.wfile.write(json.dumps(config).encode())
    
    def _handle_search(self, query_params):
        """å¤„ç†æœç´¢è¯·æ±‚"""
        query = query_params.get('query', [''])[0].upper()
        limit = int(query_params.get('limit', [10])[0])
        
        results = []
        for symbol, config in STOCK_CONFIGS.items():
            if query in symbol or query in config.name.upper():
                results.append({
                    "symbol": symbol,
                    "full_name": config.name,
                    "description": f"{config.name} - {config.sector}",
                    "exchange": "NASDAQ",
                    "type": "stock"
                })
            if len(results) >= limit:
                break
        
        self.wfile.write(json.dumps(results).encode())
    
    def _handle_symbols(self, query_params):
        """å¤„ç†è‚¡ç¥¨ä¿¡æ¯è¯·æ±‚"""
        symbol = query_params.get('symbol', [''])[0]
        
        if symbol in STOCK_CONFIGS:
            config = STOCK_CONFIGS[symbol]
            symbol_info = {
                "name": symbol,
                "exchange-traded": "NASDAQ",
                "exchange-listed": "NASDAQ",
                "timezone": "America/New_York",
                "minmov": 1,
                "minmov2": 0,
                "pointvalue": 1,
                "session": "0930-1600",
                "has_intraday": True,
                "has_no_volume": False,
                "description": config.name,
                "pricescale": 100,
                "supported_resolutions": ["1", "5", "15", "30", "60", "D", "W", "M"],
                "volume_precision": 0,
                "data_status": "streaming"
            }
        else:
            symbol_info = {}
        
        self.wfile.write(json.dumps(symbol_info).encode())
    
    def _handle_history(self, query_params):
        """å¤„ç†å†å²æ•°æ®è¯·æ±‚"""
        symbol = query_params.get('symbol', [''])[0]
        resolution = query_params.get('resolution', ['D'])[0]
        from_time = int(query_params.get('from', [0])[0])
        to_time = int(query_params.get('to', [0])[0])
        
        if symbol not in STOCK_CONFIGS:
            self.wfile.write(json.dumps({"s": "no_data"}).encode())
            return
        
        # è·å–æ•°æ®
        df = self.server_instance.get_daily_data(symbol, days=500)
        
        if df.empty:
            self.wfile.write(json.dumps({"s": "no_data"}).encode())
            return
        
        # è½¬æ¢æ—¶é—´æˆ³
        df['timestamp'] = df['date'].apply(lambda x: int(x.timestamp()))
        
        # è¿‡æ»¤æ—¶é—´èŒƒå›´
        mask = (df['timestamp'] >= from_time) & (df['timestamp'] <= to_time)
        filtered_df = df.loc[mask]
        
        if filtered_df.empty:
            self.wfile.write(json.dumps({"s": "no_data"}).encode())
            return
        
        # å‡†å¤‡è¿”å›æ•°æ®
        result = {
            "s": "ok",
            "t": filtered_df['timestamp'].tolist(),
            "o": filtered_df['open'].tolist(),
            "h": filtered_df['high'].tolist(),
            "l": filtered_df['low'].tolist(),
            "c": filtered_df['close'].tolist(),
            "v": filtered_df['volume'].tolist()
        }
        
        self.wfile.write(json.dumps(result).encode())
    
    def _handle_time(self):
        """å¤„ç†æ—¶é—´è¯·æ±‚"""
        self.wfile.write(json.dumps(int(time.time())).encode())
    
    def do_OPTIONS(self):
        """å¤„ç†CORSé¢„æ£€è¯·æ±‚"""
        self.send_response(200)
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'X-Requested-With')
        self.end_headers()

def run_server(port=8080):
    """å¯åŠ¨å¢å¼ºçš„UDFæœåŠ¡å™¨"""
    server_address = ('', port)
    httpd = HTTPServer(server_address, UDFRequestHandler)
    
    print(f'ğŸš€ Enhanced UDF Server starting on port {port}...')
    print(f'ğŸ“Š Available symbols: {", ".join(STOCK_CONFIGS.keys())}')
    print('\nğŸ“ API Endpoints:')
    print('  ğŸ“‹ /config          - é…ç½®ä¿¡æ¯')
    print('  ğŸ” /search?query=   - æœç´¢è‚¡ç¥¨')
    print('  ğŸ“ˆ /symbols?symbol= - è‚¡ç¥¨è¯¦æƒ…')
    print('  ğŸ“Š /history?symbol= - å†å²æ•°æ®')
    print('  â° /time            - å½“å‰æ—¶é—´æˆ³')
    print(f'\nğŸŒ TradingView datafeed URL: http://localhost:{port}')
    print('\nğŸ’¡ Features:')
    print('  âœ… Realistic OHLCV data generation')
    print('  âœ… Multiple stock symbols with different characteristics')
    print('  âœ… Volume patterns simulation')
    print('  âœ… Trend and seasonality effects')
    print('  âœ… Data caching for better performance')
    print('\nğŸ”„ Data regenerates with realistic market behavior patterns')
    print('â¹ï¸  Press Ctrl+C to stop the server\n')
    
    try:
        httpd.serve_forever()
    except KeyboardInterrupt:
        print('\nğŸ›‘ Shutting down server...')
        httpd.server_close()
        print('âœ… Server stopped successfully')

if __name__ == '__main__':
    port = int(sys.argv[1]) if len(sys.argv) > 1 else 8080
    run_server(port)